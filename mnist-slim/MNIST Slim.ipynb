{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using slim to Build Model Architectures\n",
    "\n",
    "This notebook gives a simple example of using Tensorflow's [slim library](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim) to construct a \"deeper\" learning architecture for the MNIST dataset. We'll see how easy it is to construct architectures, and how to output simple summaries from Tensorboard.\n",
    "\n",
    "As a simple example, we'll use the architecture presented in Michael Nielsen's online [textbook](http://neuralnetworksanddeeplearning.com/chap6.html). This knowledge will later become useful as we explore more complicated architectures like [Inception](https://github.com/tensorflow/models/blob/master/inception/inception/slim/inception_model.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data as mnist_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Read in MNIST dataset, compute mean / standard deviation of the training images\n",
    "mnist = mnist_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "MEAN = np.mean(mnist.train.images)\n",
    "STD = np.std(mnist.train.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convenience method for reshaping images. The included MNIST dataset stores images\n",
    "# as Nx784 row vectors. This method reshapes the inputs into Nx28x28x1 images that are\n",
    "# better suited for convolution operations and rescales the inputs so they have a\n",
    "# mean of 0 and unit variance.\n",
    "def resize_images(images):\n",
    "    reshaped = (images - MEAN)/STD\n",
    "    reshaped = np.reshape(reshaped, [-1, 28, 28, 1])\n",
    "    \n",
    "    assert(reshaped.shape[1] == 28)\n",
    "    assert(reshaped.shape[2] == 28)\n",
    "    assert(reshaped.shape[3] == 1)\n",
    "    \n",
    "    return reshaped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NielsenNet\n",
    "\n",
    "The neural net architecture presented by Michael Nielsen in chapter 6 of his textbook achieves an accuracy in excess of 99%. I've dubbed this architecture _NielsenNet_. It consists of two convolution layers, followed by two fully connected neural network layers, followed by an output layer. Dropout is used to after each fully-connected layer to control overfitting.\n",
    "\n",
    "When building this model using slim, we'll use the built-in `conv2d` and `max_pool` functions to build the convlution layers, changing 28x28 input images into 5x5x40 outputs for the fully connected layer. We'll do this with a combination of different padding modes (`SAME` vs `VALID`) and max-pooling.\n",
    "\n",
    "Finally we'll build a succession of fully-connected layers using the `fully_connected` convenience method. Dropout can be implemented using slim's `dropout` method, gated by the `is_training` tensor.\n",
    "\n",
    "Building the network by successively mutating the `net` variable is pretty common, and something we'll see later on in the Inception architecture ([peek here](https://github.com/tensorflow/models/blob/master/inception/inception/slim/inception_model.py#L107))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nielsen_net(inputs, is_training, scope='NielsenNet'):\n",
    "    with tf.variable_scope(scope, 'NielsenNet'):\n",
    "        # First Group: Convolution + Pooling 28x28x1 => 28x28x20 => 14x14x20\n",
    "        net = slim.conv2d(inputs, 20, [5, 5], padding='SAME', scope='layer1-conv')\n",
    "        net = slim.max_pool2d(net, 2, stride=2, scope='layer2-max-pool')\n",
    "\n",
    "        # Second Group: Convolution + Pooling 14x14x20 => 10x10x40 => 5x5x40\n",
    "        net = slim.conv2d(net, 40, [5, 5], padding='VALID', scope='layer3-conv')\n",
    "        net = slim.max_pool2d(net, 2, stride=2, scope='layer4-max-pool')\n",
    "\n",
    "        # Reshape: 5x5x40 => 1000x1\n",
    "        net = tf.reshape(net, [-1, 5*5*40])\n",
    "\n",
    "        # Fully Connected Layer: 1000x1 => 1000x1\n",
    "        net = slim.fully_connected(net, 1000, scope='layer5')\n",
    "        net = slim.dropout(net, is_training=is_training, scope='layer5-dropout')\n",
    "\n",
    "        # Second Fully Connected: 1000x1 => 1000x1\n",
    "        net = slim.fully_connected(net, 1000, scope='layer6')\n",
    "        net = slim.dropout(net, is_training=is_training, scope='layer6-dropout')\n",
    "\n",
    "        # Output Layer: 1000x1 => 10x1\n",
    "        net = slim.fully_connected(net, 10, scope='output')\n",
    "        net = slim.dropout(net, is_training=is_training, scope='output-dropout')\n",
    "\n",
    "        return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# Create the placeholder tensors for the input images (x), the training labels (y_actual)\n",
    "# and whether or not dropout is active (is_training)\n",
    "x = tf.placeholder(tf.float32, shape=[None, 28, 28, 1], name='Inputs')\n",
    "y_actual = tf.placeholder(tf.float32, shape=[None, 10], name='Labels')\n",
    "is_training = tf.placeholder(tf.bool, name='IsTraining')\n",
    "\n",
    "# Pass the inputs into nielsen_net, outputting the logits\n",
    "logits = nielsen_net(x, is_training, scope='NielsenNetTrain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use the logits to create four additional operations:\n",
    "#\n",
    "# 1: The cross entropy of the predictions vs. the actual labels\n",
    "# 2: The number of correct predictions\n",
    "# 3: The accuracy given the number of correct predictions\n",
    "# 4: The update step, using the MomentumOptimizer\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, y_actual))\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y_actual, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "train_step = tf.train.MomentumOptimizer(0.01, 0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To monitor our progress using tensorboard, create two summary operations\n",
    "# to track the loss and the accuracy\n",
    "loss_summary = tf.summary.scalar('loss', cross_entropy)\n",
    "accuracy_summary = tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "train_writer = tf.summary.FileWriter('/tmp/nielsen-net', sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:     0, Validation Accuracy = 10.60%\n",
      "Step:  1000, Validation Accuracy = 96.74%\n",
      "Step:  2000, Validation Accuracy = 97.78%\n",
      "Step:  3000, Validation Accuracy = 98.26%\n",
      "Step:  4000, Validation Accuracy = 98.42%\n",
      "Step:  5000, Validation Accuracy = 98.66%\n",
      "Step:  6000, Validation Accuracy = 98.84%\n",
      "Step:  7000, Validation Accuracy = 98.88%\n",
      "Step:  8000, Validation Accuracy = 98.88%\n",
      "Step:  9000, Validation Accuracy = 98.96%\n",
      "Step: 10000, Validation Accuracy = 98.94%\n",
      "Step: 11000, Validation Accuracy = 99.06%\n",
      "Step: 12000, Validation Accuracy = 99.12%\n",
      "Step: 13000, Validation Accuracy = 99.10%\n",
      "Step: 14000, Validation Accuracy = 99.16%\n",
      "Step: 15000, Validation Accuracy = 99.04%\n",
      "Step: 16000, Validation Accuracy = 99.20%\n",
      "Step: 17000, Validation Accuracy = 99.16%\n",
      "Step: 18000, Validation Accuracy = 99.18%\n",
      "Step: 19000, Validation Accuracy = 99.16%\n",
      "Step: 20000, Validation Accuracy = 99.22%\n",
      "Step: 21000, Validation Accuracy = 99.26%\n",
      "Step: 22000, Validation Accuracy = 99.24%\n",
      "Step: 23000, Validation Accuracy = 99.26%\n",
      "Step: 24000, Validation Accuracy = 99.32%\n",
      "Step: 25000, Validation Accuracy = 99.34%\n",
      "Step: 26000, Validation Accuracy = 99.32%\n",
      "Step: 27000, Validation Accuracy = 99.32%\n",
      "Step: 28000, Validation Accuracy = 99.34%\n",
      "Step: 29000, Validation Accuracy = 99.36%\n",
      "Step: 30000, Validation Accuracy = 99.30%\n",
      "Step: 31000, Validation Accuracy = 99.36%\n",
      "Step: 32000, Validation Accuracy = 99.28%\n",
      "Step: 33000, Validation Accuracy = 99.38%\n",
      "Step: 34000, Validation Accuracy = 99.38%\n",
      "Step: 35000, Validation Accuracy = 99.38%\n",
      "Step: 36000, Validation Accuracy = 99.40%\n",
      "Step: 37000, Validation Accuracy = 99.36%\n",
      "Step: 38000, Validation Accuracy = 99.34%\n",
      "Step: 39000, Validation Accuracy = 99.42%\n",
      "Step: 40000, Validation Accuracy = 99.38%\n",
      "Step: 41000, Validation Accuracy = 99.40%\n",
      "Step: 42000, Validation Accuracy = 99.40%\n",
      "Step: 43000, Validation Accuracy = 99.42%\n",
      "Step: 44000, Validation Accuracy = 99.38%\n",
      "Step: 45000, Validation Accuracy = 99.42%\n",
      "Step: 46000, Validation Accuracy = 99.40%\n",
      "Step: 47000, Validation Accuracy = 99.30%\n",
      "Step: 48000, Validation Accuracy = 99.38%\n",
      "Step: 49000, Validation Accuracy = 99.30%\n",
      "Step: 50000, Validation Accuracy = 99.44%\n",
      "Step: 51000, Validation Accuracy = 99.38%\n",
      "Step: 52000, Validation Accuracy = 99.42%\n",
      "Step: 53000, Validation Accuracy = 99.46%\n",
      "Step: 54000, Validation Accuracy = 99.44%\n",
      "Step: 55000, Validation Accuracy = 99.42%\n",
      "Step: 56000, Validation Accuracy = 99.38%\n",
      "Step: 57000, Validation Accuracy = 99.40%\n",
      "Step: 58000, Validation Accuracy = 99.44%\n",
      "Step: 59000, Validation Accuracy = 99.38%\n",
      "Step: 60000, Validation Accuracy = 99.44%\n",
      "Step: 61000, Validation Accuracy = 99.38%\n",
      "Step: 62000, Validation Accuracy = 99.42%\n",
      "Step: 63000, Validation Accuracy = 99.42%\n",
      "Step: 64000, Validation Accuracy = 99.42%\n",
      "Step: 65000, Validation Accuracy = 99.38%\n",
      "Step: 66000, Validation Accuracy = 99.44%\n",
      "Step: 67000, Validation Accuracy = 99.38%\n",
      "Step: 68000, Validation Accuracy = 99.30%\n",
      "Step: 69000, Validation Accuracy = 99.42%\n",
      "Step: 70000, Validation Accuracy = 99.40%\n",
      "Step: 71000, Validation Accuracy = 99.36%\n",
      "Step: 72000, Validation Accuracy = 99.40%\n",
      "Step: 73000, Validation Accuracy = 99.38%\n",
      "Step: 74000, Validation Accuracy = 99.40%\n",
      "Step: 75000, Validation Accuracy = 99.36%\n",
      "Step: 76000, Validation Accuracy = 99.40%\n",
      "Step: 77000, Validation Accuracy = 99.40%\n",
      "Step: 78000, Validation Accuracy = 99.38%\n",
      "Step: 79000, Validation Accuracy = 99.38%\n",
      "Step: 80000, Validation Accuracy = 99.44%\n",
      "Step: 81000, Validation Accuracy = 99.40%\n",
      "Step: 82000, Validation Accuracy = 99.44%\n",
      "Step: 83000, Validation Accuracy = 99.48%\n",
      "Step: 84000, Validation Accuracy = 99.44%\n",
      "Step: 85000, Validation Accuracy = 99.46%\n",
      "Step: 86000, Validation Accuracy = 99.48%\n",
      "Step: 87000, Validation Accuracy = 99.44%\n",
      "Step: 88000, Validation Accuracy = 99.42%\n",
      "Step: 89000, Validation Accuracy = 99.48%\n",
      "Step: 90000, Validation Accuracy = 99.42%\n",
      "Step: 91000, Validation Accuracy = 99.42%\n",
      "Step: 92000, Validation Accuracy = 99.48%\n",
      "Step: 93000, Validation Accuracy = 99.44%\n",
      "Step: 94000, Validation Accuracy = 99.44%\n",
      "Step: 95000, Validation Accuracy = 99.46%\n",
      "Step: 96000, Validation Accuracy = 99.48%\n",
      "Step: 97000, Validation Accuracy = 99.44%\n",
      "Step: 98000, Validation Accuracy = 99.48%\n",
      "Step: 99000, Validation Accuracy = 99.38%\n"
     ]
    }
   ],
   "source": [
    "eval_data = {\n",
    "    x: resize_images(mnist.validation.images),\n",
    "    y_actual: mnist.validation.labels,\n",
    "    is_training: False\n",
    "}\n",
    "\n",
    "for i in xrange(100000):\n",
    "    images, labels = mnist.train.next_batch(100)\n",
    "    summary, _ = sess.run([loss_summary, train_step], feed_dict={x: resize_images(images), y_actual: labels, is_training: True})\n",
    "    train_writer.add_summary(summary, i)\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        summary, acc = sess.run([accuracy_summary, accuracy], feed_dict=eval_data)\n",
    "        train_writer.add_summary(summary, i)\n",
    "        print(\"Step: %5d, Validation Accuracy = %5.2f%%\" % (i, acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 99.51%\n"
     ]
    }
   ],
   "source": [
    "test_data = {\n",
    "    x: resize_images(mnist.test.images),\n",
    "    y_actual: mnist.test.labels,\n",
    "    is_training: False\n",
    "}\n",
    "\n",
    "acc = sess.run(accuracy, feed_dict=test_data)\n",
    "\n",
    "print(\"Test Accuracy = %5.2f%%\" % (100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
